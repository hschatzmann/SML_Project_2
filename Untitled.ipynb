{
 "cells": [
  {
   "cell_type": "code",
   "id": "30da20f1-f0a4-4730-918f-22169741fb2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T22:05:12.522931Z",
     "start_time": "2024-05-24T22:05:12.514913Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "IMAGE_SIZE = (252, 378)\n",
    "def load_mask(mask_path):\n",
    "    \"\"\"Loads the segmentation mask from the specified path.\n",
    "    Inputs:\n",
    "        mask_path (str): the path from which the segmentation mask will be read.\n",
    "        It should have the format \"/PATH/TO/LOAD/DIR/XXXX_mask.png\".\n",
    "    Outputs:\n",
    "        mask (np.array): segmentation mask as a numpy array.\n",
    "    \"\"\"\n",
    "    mask = np.asarray(Image.open(mask_path)).astype(np.uint8)  # Ensure mask is uint8\n",
    "    if mask.max() > 1:\n",
    "        mask = mask // 255\n",
    "    return mask\n",
    "def compute_iou(pred_mask, gt_mask, eps=1e-6):\n",
    "    \"\"\"Computes the IoU between two numpy arrays: pred_mask and gt_mask.\n",
    "    Inputs:\n",
    "        pred_mask (np.array): dtype:int, shape:(image_height, image_width), values are 0 or 1.\n",
    "        gt_mask (np.array): dtype:int, shape:(image_height, image_width), values are 0 or 1.\n",
    "        eps (float): epsilon to smooth the division in order to avoid 0/0.\n",
    "    Outputs:\n",
    "        iou_score (float)\n",
    "    \"\"\"\n",
    "    intersection = (\n",
    "        (pred_mask & gt_mask).astype(float).sum()\n",
    "    )  # will be zero if gt=0 or pred=0\n",
    "    union = (pred_mask | gt_mask).astype(float).sum()  # will be zero if both are 0\n",
    "    iou = (intersection + eps) / (\n",
    "        union + eps\n",
    "    )  # we smooth our division by epsilon to avoid 0/0\n",
    "    iou_score = iou.mean()\n",
    "    return iou_score"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a8f506e-dae0-44c6-acc7-ce00e1eec961",
   "metadata": {},
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "class ETHMugsDataset(Dataset):\n",
    "    \"\"\"Torch dataset for ETH Mugs.\"\"\"\n",
    "    def __init__(self, root_dir, mode=\"train\"):\n",
    "        \"\"\"\n",
    "        This dataset class loads the ETH Mugs dataset.\n",
    "        Args:\n",
    "            root_dir (str): Path to the root directory of the dataset.\n",
    "            mode (str): Mode of the dataset. It can be \"train\", \"val\" or \"test\"\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.root_dir = root_dir\n",
    "        self.rgb_dir = os.path.join(self.root_dir, \"rgb\")\n",
    "        self.mask_dir = os.path.join(self.root_dir, \"masks\") if mode != \"test\" else None\n",
    "        self.image_paths = [os.path.join(self.rgb_dir, fname) for fname in os.listdir(self.rgb_dir) if fname.endswith('.jpg')]\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(IMAGE_SIZE),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        self.mask_transform = transforms.Compose([\n",
    "            transforms.Resize(IMAGE_SIZE),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        print(\"[INFO] Dataset mode:\", mode)\n",
    "        print(f\"[INFO] Number of images in the ETHMugsDataset: {len(self.image_paths)}\")\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    def __getitem__(self, idx: int):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        if self.mode != \"test\":\n",
    "            # Adjusting mask file name and path\n",
    "            base_filename = os.path.basename(image_path).replace('_rgb.jpg', '_mask.png')\n",
    "            mask_path = os.path.join(self.mask_dir, base_filename)\n",
    "            if not os.path.exists(mask_path):\n",
    "                raise FileNotFoundError(f\"Mask file {mask_path} not found.\")\n",
    "            mask = load_mask(mask_path)\n",
    "            mask = Image.fromarray(mask.astype(np.uint8))  # Convert to PIL Image in uint8\n",
    "            mask = self.mask_transform(mask)\n",
    "        else:\n",
    "            mask = torch.tensor([])  # Empty tensor for test mode\n",
    "        return image, mask"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b185fa-08f7-4aaa-932e-9b984713c1df",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "# Initialize dataset and dataloader\n",
    "train_dataset = ETHMugsDataset(root_dir='/Users/michaelaernst/Documents/Fabian/ETH/ML Projekte/student_template2/project2/datasets/train_images_378_252', mode='train')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_dataset = ETHMugsDataset(root_dir='/Users/michaelaernst/Documents/Fabian/ETH/ML Projekte/student_template2/project2/datasets/train_images_378_252', mode='val')\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "# Training loop\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, masks in train_dataloader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_dataloader):.4f}\")\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_iou = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_images, val_masks in val_dataloader:\n",
    "            val_images = val_images.to(device)\n",
    "            val_masks = val_masks.to(device)\n",
    "            val_outputs = model(val_images)\n",
    "            val_outputs = torch.sigmoid(val_outputs)\n",
    "            val_outputs = (val_outputs > 0.5).float()\n",
    "            val_outputs_np = val_outputs.cpu().numpy().astype(int)\n",
    "            val_masks_np = val_masks.cpu().numpy().astype(int)\n",
    "            for val_output_np, val_mask_np in zip(val_outputs_np, val_masks_np):\n",
    "                total_iou += compute_iou(val_output_np, val_mask_np)\n",
    "    avg_iou = total_iou / len(val_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation IoU: {avg_iou:.4f}\")\n",
    "    # Visualize a sample output\n",
    "    val_images, val_masks = next(iter(val_dataloader))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_images = val_images.to(device)\n",
    "        val_outputs = model(val_images)\n",
    "        val_outputs = torch.sigmoid(val_outputs)\n",
    "        val_outputs = (val_outputs > 0.5).float()\n",
    "    # Plot the image, ground truth mask, and predicted mask\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(val_images[0].cpu().permute(1, 2, 0))\n",
    "    plt.title('Image')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(val_masks[0].cpu().squeeze(), cmap='gray')\n",
    "    plt.title('Ground Truth Mask')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(val_outputs[0].cpu().squeeze(), cmap='gray')\n",
    "    plt.title('Predicted Mask')\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245b3dbd-7282-457d-945a-067f1bd55e61",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427bbcbf-d73e-4bc2-9684-98780c8f303e",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
